---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: inference-service-ingress-v2-secure
  annotations:
    cert-manager.io/cluster-issuer: production
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/limit-rps: "5"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-body-size: "16m"
    nginx.ingress.kubernetes.io/proxy-buffer-size: "8k"
    nginx.ingress.kubernetes.io/limit-connections: "20"
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-origin: "https://spred.io"
    nginx.ingress.kubernetes.io/cors-allow-credentials: "true"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, PUT, POST, DELETE, PATCH, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "Authorization,Content-Type,X-Requested-With,Accept,Origin,Referer,x-client-deviceid,User-Agent"
    nginx.ingress.kubernetes.io/cors-expose-headers: "Content-Length,Content-Range"
    nginx.ingress.kubernetes.io/cors-max-age: "86400"
spec:
  ingressClassName: external-nginx
  rules:
    - host: api.spred.io
      http:
        paths:
          - path: /inference
            pathType: Prefix
            backend:
              service:
                name: inference-service
                port:
                  number: 8080
  tls:
    - hosts:
        - api.spred.io
      secretName: api-spred-io